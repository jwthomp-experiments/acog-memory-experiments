Experimenting with building a memory system for conversational ai

Requires gpt4all model in a models subfolder. Currently using a gpq4all-lora-unfiltered-quantized.bin model that has been converted.

You can obtain the unfiltered model from here:
- https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-unfiltered-quantized.bin

You will need to convert it per the instructions found here:
https://github.com/nomic-ai/pyllamacpp#gpt4all
